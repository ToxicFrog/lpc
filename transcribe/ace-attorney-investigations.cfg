# This is where the font files specific to this game generated by the OCR program
# will be stored.
FONTDIR="$BASEDIR/aai/"

# Called on each image to inspect it and optionally extract text.
# If text is found, it should call `ocr` to extract the text and then `output`
# to write it to the transcript file.
function READ {
  # The various detect-foo functions are at the bottom.
  if detect-top; then
    # ocr takes a key as its first argument; this can be used with 'get' later
    # (in WRITE) to retrieve the text that was OCRd. This also determines which
    # character recognition database is used, so here (for example) the nameplate
    # and the main text use different recognition databases (because they have
    # different fonts). There is not currently support for reading different
    # parts of the image using the same db.
    # Everything after that argument is arguments to imagemagick to extract and
    # preprocess the section of image that's going to be OCRd.
    ocr nameplate -crop 88x20+4+110 -intensity Rec709Luma -threshold 90% -negate
    ocr text -crop 464x102+16+4 -intensity Brightness -threshold 90% -negate
    # Output just does some setup and then calls WRITE, below. If you don't
    # output, nothing will be written to the transcript file no matter how much
    # text you OCRd!
    output
    return
  fi

  if detect-bottom; then
    ocr nameplate -crop 88x20+4+254 -intensity Rec709Luma -threshold 90% -negate
    ocr text -crop 464x102+16+278 -intensity Brightness -threshold 90% -negate
    output
    return
  fi

  if detect-bottom-offset; then
    ocr nameplate -crop 88x20+4+206 -intensity Rec709Luma -threshold 90% -negate
    ocr text -crop 464x102+16+230 -intensity Brightness -threshold 90% -negate
    output
    return
  fi
}

# Called by 'output'. Anything written to stdout is appended to the transcription
# file. Note the use of 'get' to extract the text that was OCRd before.
# To display status messages to the user, write them to stderr.
function WRITE {
  echo "# $IMAGE"
  echo "[$(get nameplate)] $(get text)"
  echo ""
}

# The POST functions are used for postprocessing. All of them have a name of the
# form POST/<key passed to OCR>. You need to define all of these even if they
# don't do anything! In that case just do: function POST/whatever { cat; }
# These are used to handle consistent errors in the OCR and cases where the
# OCRd text is correct but would be more readable formatted differently.
function POST/nameplate {
  # Remove leading and trailing whitespace, and collapse '?? ' into '? ' since
  # a pecularity of OCRing '? ? ?' in the nameplate causes it to render as
  # '?? ?? ?? ' instead.
  sed -E 's/\?\? /\? /g; s/^ +//; s/ +$//'
}

function POST/text {
  # Staple multiple lines together into a single long line.
  tr '\n' ' ' \
    | sed -E "
      # Replace things like I,m and it,s with I'm and it's, since the OCR has
      # trouble distinguishing between ' and ,
      s/([A-Za-z]),([A-Za-z])/\\1'\\2/g

      # It tends to read '...' as '. . . ', so fix that
      s/\\. \\. \\. /.../g
      # Also tends to one doublequote as two
      s/\"\"/\"/g

      # Trim whitespace before closing paren.
      s/ +\)/)/g

      # Remove leading and trailing whitespace
      s/^ +//; s/ +$//
    "
}

# Functions for detecting whether there is or is not text.
# This turns out to be fairly hard in AAI, since the decorative frame around the
# text is partially transparent! So we can't do pixel-perfect detection like in
# Septerra Core.
# Instead, we examine five 4x4 areas which correspond to corners of the text
# frame and nameplate frame (which are visually 2x2 because AAI uses 2x2 cells
# for these UI elements), threshold them so that exactly one cell becomes
# white/black and the rest black/white, and compare them against test patterns.
# If all of them match, we can be pretty confident that we've found a screenshot
# with text on it.
# The test patterns are just named based on the shape of the pattern: top left,
# top right, bottom left, bottom right. So WBWW is an L shape.

# Detect text at the top of the screen.
function detect-top {
  # Top left, top right, NP top left, NP top right, NP bottom left
  corner BBBW 90% 0 0 &&
  corner BBWB 90% 508 0 &&
  corner WBWW 10% 0 106 &&
  corner WBWW 10% 92 106 &&
  corner WWBW 10% 0 130
}

# Detect text at the bottom.
function detect-bottom {
  # NP top left, NP bottom left, NP bottom right, bottom left, bottom right
  corner BWWW 10% 0 250 &&
  corner WWWB 10% 0 274 &&
  corner WWWB 10% 92 274 &&
  corner BWBB 90% 0 380 &&
  corner WBBB 90% 508 380
}

# Detect text at the bottom that's been shoved upwards by a "use the touchscreen"
# panel.
function detect-bottom-offset {
  # As above, but shifted 48px upwards
  corner BWWW 10% 0 202 &&
  corner WWWB 10% 0 226 &&
  corner WWWB 10% 92 226 &&
  corner BWBB 90% 0 332 &&
  corner WBBB 90% 508 332
}

# Helper function for the above.
function corner {
  # detect <max delta> <pattern> <args...>
  # processes the current image using args, then compares it to the pattern.
  # outputs a number equal to the number of different pixels.
  # if that's <= the max delta, succeeds; otherwise fails.
  # note that it doesn't matter how similar two pixels are; if they differ *at all*
  # this is considered a difference. So it's recommended to threshold your images
  # unless you're looking for a pixel-perfect match.
  detect 0 "$BASEDIR/aai/$1.png" \
    -crop 4x4+$3+$4 -colorspace Gray -normalize -threshold $2
}

